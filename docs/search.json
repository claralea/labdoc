[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "File search",
    "section": "",
    "text": "Find a file using the table bellow."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Tools",
    "section": "",
    "text": "NER takes as input raw text and returns the main CUIs for a given .txt file.\n\nGo to /n/data1/hsph/biostat/celehs/lab/NER/NER_AllInOne\nGo to the folder /articles, save the input text file there under the name Articles.txt\nTo run NER on each line separately, use the line separator -[wiki_article_start]\nGo to the folder /NER_AllInOne and run NER\n\n\nmodule load gcc\nmodule load java\nsh runMiniNERAllInOne.sh\n\n\nThe results are saved as NER_output.txt in the folder /results. The dropped CUIs are displayed in the terminal.\n\n\n\n\n\nCreate a new folder and upload and unzip the contents of ppmi-svd-master in the new folder.\nThen activate your conda environment using `conda activate ppmi` or `source activate path_of_your_conda_env`. Get the path of your environment using `conda env list`\ninstall the package slepc=3.12 using `conda install -c conda-forge slepc=3.12`. Even if there is an error in this step, you can continue with the following:\nGo to ppmi-svd-master folder and do the following- There might still be errors in this step - these would mostly for the embedding calculator\n\n\nmkdir build\ncd build\ncmake ..\nmake -j 5\n\n\nA bin folder will be created inside ../ppmi_svd_master. If you can see the the executable “enumeratepairs” then you should be all set.\n\n\n\n\nDetailed information on NILE can be found in the [NILE user guide](https://celehs.github.io/NILE_User_Guide_2019.pdf).\n\nSet up the environment variable for NLP to run.\n\n\\textbf{Option 1:} Edit your ~/.bashrc file and add the following export command to it:\n\nexport NLP_INTF_HOME=\"/n/data1/hsph/biostat/celehs/lab/NLP/NLP_ORACLE\"\n\nThen restart the session to reflect the changes. Now every time a session is started, the environment variable is set up.\n\\textbf{Option 2:} Use the following command before running NLP on O2:\n\nexport NLP_INTF_HOME=\"/n/data1/hsph/biostat/celehs/lab/NLP/NLP_ORACLE\"\n\n\nMake the Database Connection. The file NLPproperties.txt is located here:\n\n/n/data1/hsph/biostat/celehs/lab/NLP/NLP\\textunderscore ORACLE/project/uu/input/NLPproperties.txt\nIn order to make the database connection, edit the file NLPproperties.txt so that it contains the required information.\n\nSave the dictionary in the path specified in the above NLPproperties.txt file under \\textcolor{BrickRed}{uu\\textunderscore dict.txt}\nFrom the terminal, go back to the main folder \\textcolor{BrickRed}{/n/data1/hsph/biostat/celehs/lab/NLP/NLP\\textunderscore ORACLE} and run:\n\n\nmodule load java\nrun mysql_runnile.sh\n\n\nThe output will be generated here:\n/n/data1/hsph/biostat/celehs/lab/NLP/NLP_ORACLE/project/uu/OUTPUT\nThe warning and eventual error messages will be logged here:\n/n/data1/hsph/biostat/celehs/lab/NLP/NLP_ORACLE/project/uu/log"
  },
  {
    "objectID": "mgb_setup.html",
    "href": "mgb_setup.html",
    "title": "Setting up the MGB workspace",
    "section": "",
    "text": "1. Installing the VPN\n\nThe instructions for installing the VPN can be obtained \\href{ https://www.partners.org/vpn/Token-Less-VPN.pdf}{here}\nOn Cisco AnyConnect, connect to pvc.partners.org/saml, then enter your credentials\n\n2. Setting up ErisONE\n\nSubmit the following \\href{ https://rc.partners.org/erisone-cluster-account-request}{request form} to obtain access to ERISOne.\nFollow the instructions provided in the \\href{https://rc.partners.org/kb/article/2814}{Quick Start guide}.\n\\href{https://rc.partners.org/kb/computational-resources/faq-erisone?article=3476}{Documentation} on submitting jobs and job resources at ERISOne\nYou may access Partner’s \\href{https://rstudio.partners.org}{RStudio} instead of creating an interactive R session.\n\n\nSetting up the Microsoft virtual desktop\n\n\nIn order to create a Windows Analysis Server account (HPCWIN3) and access to the virtual desktop, submit the following \\href{ https://rc.partners.org/windows-analysis-server-account-request}{request form}\nDownload and install Microsoft Remote Desktop (you can download it \\href{https://apps.apple.com/us/app/microsoft-remote-desktop-10/id1295203466?mt=12}{here} for example).\nCreate a new connection. Connect to HPCWin3 using hpcwin3.research.partners.org. Enter the \\href{ https://rc.partners.org/kb/article/2599}{following information} in order to connect to the virtual desktop.\n\n\nAccessing the data from the Microsoft virtual desktop\n\n\nOpen Microsoft SQL server\nLogin by selecting Database Engine and SQL server authentication\nSever type: Database engine\nServer name: phsqlrpdr322.partners.org\n\nAuthentification: SQL server authentification\n\nThe password is found in Properties.txt file. An example of this files is located here:\\\\ \\textcolor{BrickRed}{/data/pdc/NLP/Delivery\\textunderscore run\\textunderscore 80K/i2b2DownloaderProperties.txt}\nThe only database directly accessible to us is Biobank\\textunderscore Note\\textunderscore Review. For the other databases, an IRB is necessary.\nThe main database of interest is located in BiobankNote\\textunderscore Review and is called observation\\textunderscore fact. The latest is observation\\textunderscore fact\\textunderscore\\textunderscore 20201124\\textunderscore 592, and the dataset observation\\textunderscore fact points to the latest data. The dataset contains codified data as well as textual data, located in the column OBSERVATION\\textunderscore BLOB."
  }
]